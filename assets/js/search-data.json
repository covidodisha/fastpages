{
  
    
        "post0": {
            "title": "COVID-19 $R_t$",
            "content": "Based on k-sys/covid-19. . #collapse # For some reason Theano is unhappy when I run the GP, need to disable future warnings import warnings warnings.simplefilter(action=&#39;ignore&#39;, category=FutureWarning) import os import requests import pymc3 as pm import pandas as pd import numpy as np import theano import theano.tensor as tt from matplotlib import pyplot as plt from matplotlib import dates as mdates from matplotlib import ticker from datetime import date from datetime import datetime from IPython.display import clear_output %config InlineBackend.figure_format = &#39;retina&#39; . . Load State Information . #collapse url = &#39;data/india-states.csv&#39; states = pd.read_csv(url, parse_dates=[&#39;date&#39;], index_col=[&#39;state&#39;, &#39;date&#39;]).sort_index() states = states.drop([]) . . Load Patient Information . Global Covid-19 Onset/Symptom Data . #collapse def download_file(url, local_filename): &quot;&quot;&quot;From https://stackoverflow.com/questions/16694907/&quot;&quot;&quot; with requests.get(url, stream=True) as r: r.raise_for_status() with open(local_filename, &#39;wb&#39;) as f: for chunk in r.iter_content(chunk_size=8192): if chunk: # filter out keep-alive new chunks f.write(chunk) return local_filename URL = &#39;data/linelist.csv&#39; LINELIST_PATH = &#39;data/linelist.csv&#39; if not os.path.exists(LINELIST_PATH): print(&#39;Downloading file, this will take a while ~100mb&#39;) try: download_file(URL, LINELIST_PATH) clear_output(wait=True) print(&#39;Done downloading.&#39;) except: print(&#39;Something went wrong. Try again.&#39;) else: print(&#39;Already downloaded CSV&#39;) . . Already downloaded CSV . Parse &amp; Clean Patient Info . #collapse # Load the patient CSV patients = pd.read_csv( &#39;data/linelist.csv&#39;, parse_dates=False, usecols=[ &#39;date_confirmation&#39;, &#39;date_onset_symptoms&#39;], low_memory=False) patients.columns = [&#39;Onset&#39;, &#39;Confirmed&#39;] # There&#39;s an errant reversed date patients = patients.replace(&#39;01.31.2020&#39;, &#39;31.01.2020&#39;) # Only keep if both values are present patients = patients.dropna() # Must have strings that look like individual dates # &quot;2020.03.09&quot; is 10 chars long is_ten_char = lambda x: x.str.len().eq(10) patients = patients[is_ten_char(patients.Confirmed) &amp; is_ten_char(patients.Onset)] # Convert both to datetimes patients.Confirmed = pd.to_datetime( patients.Confirmed, format=&#39;%d.%m.%Y&#39;) patients.Onset = pd.to_datetime( patients.Onset, format=&#39;%d.%m.%Y&#39;) # Only keep records where confirmed &gt; onset patients = patients[patients.Confirmed &gt;= patients.Onset] . . Show Relationship between Onset of Symptoms and Confirmation . #collapse ax = patients.plot.scatter( title=&#39;Onset vs. Confirmed Dates - COVID19&#39;, x=&#39;Onset&#39;, y=&#39;Confirmed&#39;, alpha=.1, lw=0, s=10, figsize=(6,6)) formatter = mdates.DateFormatter(&#39;%m/%d&#39;) locator = mdates.WeekdayLocator(interval=2) for axis in [ax.xaxis, ax.yaxis]: axis.set_major_formatter(formatter) axis.set_major_locator(locator) . . Calculate the Probability Distribution of Delay . #collapse # Calculate the delta in days between onset and confirmation delay = (patients.Confirmed - patients.Onset).dt.days # Convert samples to an empirical distribution p_delay = delay.value_counts().sort_index() new_range = np.arange(0, p_delay.index.max()+1) p_delay = p_delay.reindex(new_range, fill_value=0) p_delay /= p_delay.sum() # Show our work fig, axes = plt.subplots(ncols=2, figsize=(9,3)) p_delay.plot(title=&#39;P(Delay)&#39;, ax=axes[0]) p_delay.cumsum().plot(title=&#39;P(Delay &lt;= x)&#39;, ax=axes[1]) for ax in axes: ax.set_xlabel(&#39;days&#39;) . . Odisha State . #collapse state = &#39;OR&#39; confirmed = states.xs(state).positive.diff().dropna() confirmed.tail() . . date 2020-04-29 7.0 2020-04-30 18.0 2020-05-01 6.0 2020-05-02 3.0 2020-05-03 2.0 Name: positive, dtype: float64 . Translate Confirmation Dates to Onset Dates . Our goal is to translate positive test counts to the dates where they likely occured. Since we have the distribution, we can distribute case counts back in time according to that distribution. To accomplish this, we reverse the case time series, and convolve it using the distribution of delay from onset to confirmation. Then we reverse the series again to obtain the onset curve. Note that this means the data will be &#39;right censored&#39; which means there are onset cases that have yet to be reported so it looks as if the count has gone down. . #collapse def confirmed_to_onset(confirmed, p_delay): assert not confirmed.isna().any() # Reverse cases so that we convolve into the past convolved = np.convolve(confirmed[::-1].values, p_delay) # Calculate the new date range dr = pd.date_range(end=confirmed.index[-1], periods=len(convolved)) # Flip the values and assign the date range onset = pd.Series(np.flip(convolved), index=dr) return onset onset = confirmed_to_onset(confirmed, p_delay) . . Adjust for Right-Censoring . Since we distributed observed cases into the past to recreate the onset curve, we now have a right-censored time series. We can correct for that by asking what % of people have a delay less than or equal to the time between the day in question and the current day. . For example, 5 days ago, there might have been 100 cases onset. Over the course of the next 5 days some portion of those cases will be reported. This portion is equal to the cumulative distribution function of our delay distribution. If we know that portion is say, 60%, then our current count of onset on that day represents 60% of the total. This implies that the total is 166% higher. We apply this correction to get an idea of what actual onset cases are likely, thus removing the right censoring. . #collapse def adjust_onset_for_right_censorship(onset, p_delay): cumulative_p_delay = p_delay.cumsum() # Calculate the additional ones needed so shapes match ones_needed = len(onset) - len(cumulative_p_delay) padding_shape = (0, ones_needed) # Add ones and flip back cumulative_p_delay = np.pad( cumulative_p_delay, padding_shape, constant_values=1) cumulative_p_delay = np.flip(cumulative_p_delay) # Adjusts observed onset values to expected terminal onset values adjusted = onset / cumulative_p_delay return adjusted, cumulative_p_delay adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay) . . Take a look at all three series: confirmed, onset and onset adjusted for right censoring. . #collapse fig, ax = plt.subplots(figsize=(5,3)) confirmed.plot( ax=ax, label=&#39;Confirmed&#39;, title=state, c=&#39;k&#39;, alpha=.25, lw=1) onset.plot( ax=ax, label=&#39;Onset&#39;, c=&#39;k&#39;, lw=1) adjusted.plot( ax=ax, label=&#39;Adjusted Onset&#39;, c=&#39;k&#39;, linestyle=&#39;--&#39;, lw=1) ax.legend(); . . Let&#39;s have the model run on days where we have enough data ~last 40 or so . Sample the Posterior with PyMC3 . We assume a poisson likelihood function and feed it what we believe is the onset curve based on reported data. We model this onset curve based on the same math in the previous notebook: . $$ I^ prime = Ie^{ gamma(R_t-1)} $$ . We define $ theta = gamma(R_t-1)$ and model $ I^ prime = Ie^{ theta} $ where $ theta$ observes a random walk. We let $ gamma$ vary independently based on known parameters for the serial interval. Therefore, we can recover $R_t$ easily by $R_t = frac{ theta}{ gamma}+1$ . The only tricky part is understanding that we&#39;re feeding in onset cases to the likelihood. So $ mu$ of the poisson is the positive, non-zero, expected onset cases we think we&#39;d see today. . We calculate this by figuring out how many cases we&#39;d expect there to be yesterday total when adjusted for bias and plugging it into the first equation above. We then have to re-bias this number back down to get the expected amount of onset cases observed that day. . #collapse class MCMCModel(object): def __init__(self, region, onset, cumulative_p_delay, window=40): # Just for identification purposes self.region = region # For the model, we&#39;ll only look at the last N self.onset = onset.iloc[-window:] self.cumulative_p_delay = cumulative_p_delay[-window:] # Where we store the results self.trace = None self.trace_index = self.onset.index[1:] def run(self, chains=1, tune=3000, draws=1000, target_accept=.95): with pm.Model() as model: # Random walk magnitude step_size = pm.HalfNormal(&#39;step_size&#39;, sigma=.03) # Theta random walk theta_raw_init = pm.Normal(&#39;theta_raw_init&#39;, 0.1, 0.1) theta_raw_steps = pm.Normal(&#39;theta_raw_steps&#39;, shape=len(self.onset)-2) * step_size theta_raw = tt.concatenate([[theta_raw_init], theta_raw_steps]) theta = pm.Deterministic(&#39;theta&#39;, theta_raw.cumsum()) # Let the serial interval be a random variable and calculate r_t serial_interval = pm.Gamma(&#39;serial_interval&#39;, alpha=6, beta=1.5) gamma = 1.0 / serial_interval r_t = pm.Deterministic(&#39;r_t&#39;, theta/gamma + 1) inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1] expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta) # Ensure cases stay above zero for poisson mu = pm.math.maximum(.1, expected_today) observed = self.onset.round().values[1:] cases = pm.Poisson(&#39;cases&#39;, mu=mu, observed=observed) self.trace = pm.sample( chains=chains, tune=tune, draws=draws, target_accept=target_accept) return self def run_gp(self): with pm.Model() as model: gp_shape = len(self.onset) - 1 length_scale = pm.Gamma(&quot;length_scale&quot;, alpha=3, beta=.4) eta = .05 cov_func = eta**2 * pm.gp.cov.ExpQuad(1, length_scale) gp = pm.gp.Latent(mean_func=pm.gp.mean.Constant(c=0), cov_func=cov_func) # Place a GP prior over the function f. theta = gp.prior(&quot;theta&quot;, X=np.arange(gp_shape)[:, None]) # Let the serial interval be a random variable and calculate r_t serial_interval = pm.Gamma(&#39;serial_interval&#39;, alpha=6, beta=1.5) gamma = 1.0 / serial_interval r_t = pm.Deterministic(&#39;r_t&#39;, theta / gamma + 1) inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1] expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta) # Ensure cases stay above zero for poisson mu = pm.math.maximum(.1, expected_today) observed = self.onset.round().values[1:] cases = pm.Poisson(&#39;cases&#39;, mu=mu, observed=observed) self.trace = pm.sample(chains=1, tune=1000, draws=1000, target_accept=.8) return self . . Run Pymc3 Model . #collapse def df_from_model(model): r_t = model.trace[&#39;r_t&#39;] mean = np.mean(r_t, axis=0) median = np.median(r_t, axis=0) hpd_90 = pm.stats.hpd(r_t, credible_interval=.9) hpd_50 = pm.stats.hpd(r_t, credible_interval=.5) idx = pd.MultiIndex.from_product([ [model.region], model.trace_index ], names=[&#39;region&#39;, &#39;date&#39;]) df = pd.DataFrame(data=np.c_[mean, median, hpd_90, hpd_50], index=idx, columns=[&#39;mean&#39;, &#39;median&#39;, &#39;lower_90&#39;, &#39;upper_90&#39;, &#39;lower_50&#39;,&#39;upper_50&#39;]) return df def create_and_run_model(name, state): confirmed = state.positive.diff().dropna() onset = confirmed_to_onset(confirmed, p_delay) adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay) return MCMCModel(name, onset, cumulative_p_delay).run() . . Handle Divergences . #collapse # Check to see if there were divergences n_diverging = lambda x: x.trace[&#39;diverging&#39;].nonzero()[0].size divergences = pd.Series([n_diverging(m) for m in models.values()], index=models.keys()) has_divergences = divergences.gt(0) print(&#39;Diverging states:&#39;) display(divergences[has_divergences]) # Rerun states with divergences for state, n_divergences in divergences[has_divergences].items(): models[state].run() . . Diverging states: . Series([], dtype: int64) . Compile Results . #collapse results = None for state, model in models.items(): df = df_from_model(model) if results is None: results = df else: results = pd.concat([results, df], axis=0) . . Render Charts . #collapse def plot_rt(name, result, ax, c=(.3,.3,.3,1), ci=(0,0,0,.05)): ax.set_ylim(0.5, 1.6) ax.set_title(name) ax.plot(result[&#39;median&#39;], marker=&#39;o&#39;, markersize=4, markerfacecolor=&#39;w&#39;, lw=1, c=c, markevery=2) ax.fill_between( result.index, result[&#39;lower_90&#39;].values, result[&#39;upper_90&#39;].values, color=ci, lw=0) ax.axhline(1.0, linestyle=&#39;:&#39;, lw=1) ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%m/%d&#39;)) ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2)) . . COVID-19 $R_t$ for Indian States . Last updated // 03 May, 2020 by Reeva . #collapse ncols = 2 nrows = int(np.ceil(results.index.levels[0].shape[0] / ncols)) fig, axes = plt.subplots( nrows=nrows, ncols=ncols, figsize=(14, nrows*3), sharey=&#39;row&#39;) for ax, (state, result) in zip(axes.flat, results.groupby(&#39;region&#39;)): plot_rt(state, result.droplevel(0), ax) fig.tight_layout() fig.set_facecolor(&#39;w&#39;) . . States and Union Territories (Short Codes) . * Andaman and Nicobar Islands (AN) * Andhra Pradesh (AP) * Arunachal Pradesh (AR) * Assam (AS) * Bihar (BR) * Chandigarh (CH) * Chhattisgarh (CT) * Dadra and Nagar Haveli (DN) * Daman and Diu (DD) * Delhi (DL) * Goa (GA) * Gujarat (GJ) * Haryana (HR) * Himachal Pradesh (HP) * Jammu and Kashmir (JK) * Jharkhand JH * Karnataka KA * Kerala KL * Ladakh LA * Lakshadweep LD * Madhya Pradesh MP * Maharashtra MH * Manipur MN * Meghalaya ML * Mizoram MZ * Nagaland NL * Odisha OR * Puducherry PY * Punjab PB * Rajasthan RJ * Sikkim SK * Tamil Nadu TN * Telangana TG * Tripura TR * Uttar Pradesh UP * Uttarakhand UT * West Bengal WB .",
            "url": "https://covidodisha.github.io/fastpages/2020/05/03/Realtime-Rt-mcmc.html",
            "relUrl": "/2020/05/03/Realtime-Rt-mcmc.html",
            "date": " • May 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Covid Odisha Main Website | Find me on Twitter | . This website is powered by fastpages and hosted on GitHub. .",
          "url": "https://covidodisha.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://covidodisha.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}